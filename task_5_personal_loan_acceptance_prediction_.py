# -*- coding: utf-8 -*-
"""Task_5_Personal Loan Acceptance Prediction .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12hzhmTHsb4FoZsOKpADc303YcEbWjkap

1) **GOAL**

my objective is to Predict which customers are likely to accept a personal loan offer using classification techniques.

2) **INTRO TO PROBLEM**

This task aims to predict which customers are likely to accept a personal loan offer using the Bank Marketing Dataset. By analyzing features like age, job, and marital status, we can build a classification model to help banks target the right customers and improve the efficiency of their marketing campaigns.

# Importing libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

"""# OBJECTIVE AND INTRO TO PROBLEM STATEMENT

# Import Data
"""

from google.colab import files
uploaded = files.upload()

#importing the dataset
df = pd.read_csv('bank.csv')
df.head() #first few rows of our csv

"""# **Data Exploration**"""

print(df.info())

#find percentage of missing values for each column
missing_values = df.isnull().mean()*100
missing_values.sum()

# Check value counts for key categorical feature
print("\nJob types:\n", df['job'].value_counts())
print("\nMarital status:\n", df['marital'].value_counts())

df.describe()

"""# **DATA VISULIZATION**"""

#Age Distribution
plt.figure(figsize=(6,5))
sns.histplot(data=df, x='age', kde=True, bins=30, color='#69b3a2', edgecolor='black', alpha=0.8)
plt.title("Distribution of Age", fontsize=16, weight='bold')
plt.xlabel("Age")
plt.ylabel("Count")
sns.despine()
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

"""This graph shows how customer ages are distributed across the dataset, with a smooth KDE curve overlay. Most customers fall between ages 25 and 50, indicating the bank targets working-age individuals.


"""

#Loan Acceptance by Job
job_loan_data = pd.crosstab(df['job'], df['deposit'], normalize='index') * 100
job_loan_data.plot(kind='bar', stacked=True, color=['#FF9999','#66B3FF'], edgecolor='black')
plt.title("Deposit Acceptance Rate by Job Type", fontsize=16)
plt.ylabel("Percentage")
plt.xticks(rotation=45)
plt.legend(["No", "Yes"], title="Deposit")
plt.grid(axis='y', linestyle='--', alpha=0.4)
plt.tight_layout()
plt.show()

"""This plot displays the percentage of customers in each job category who accepted or declined the loan. Jobs like 'admin.' and 'entrepreneur' have lower acceptance rates, while 'student' and 'retired' show higher interest."""

# Create subplot pies for each marital status
marital_types = df['marital'].unique()
fig, axes = plt.subplots(1, len(marital_types), figsize=(10,5))

colors = ['#FF9999', '#66B3FF']

for i, marital in enumerate(marital_types):
    group = df[df['marital'] == marital]
    counts = group['deposit'].value_counts()
    axes[i].pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=90, colors=colors)
    axes[i].set_title(f'{marital.title()}')

fig.suptitle("Deposit Acceptance Rate by Marital Status", fontsize=16, weight='bold')
plt.tight_layout()
plt.show()

"""The pie subplots break down each marital group's deposit decisions, showing the share of 'yes' vs 'no' within that specific group. This makes it easy to compare how likely customers in each category are to accept a deposit offer.

# **HANDLING THE MISSING VALUES**
"""

# Check how many NaN values exist in each column
print(" Missing values per column:\n")
print(df.isnull().sum())

# Drop rows with any missing (NaN) values
df = df.dropna()

# Confirm that all missing values are removed
print("\n Data shape after dropping NaNs:", df.shape)
print(" Missing values remaining:\n", df.isnull().sum().sum())

"""# **ENCODING THE FEATURES**"""

# Binary encoding
df['deposit'] = df['deposit'].map({'yes': 1, 'no': 0})
df['default'] = df['default'].map({'yes': 1, 'no': 0})
df['housing'] = df['housing'].map({'yes': 1, 'no': 0})
df['loan'] = df['loan'].map({'yes': 1, 'no': 0})

# One-hot encoding for remaining categorical variables
df_encoded = pd.get_dummies(df, columns=['job', 'marital', 'education', 'contact', 'month', 'poutcome'], drop_first=True)

"""# **Data Modeling**"""

X = df_encoded.drop('deposit', axis=1)
y = df_encoded['deposit']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **Logistic Regression Model**"""

#training the logistic regression model
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

"""# **EVALUATING THE MODEL**"""

y_pred = model.predict(X_test)

print(f"Accuracy Score: {accuracy_score(y_test, y_pred):.2f}\n")
print("Classification Report:\n", classification_report(y_test, y_pred))

"""# **CONFUSION MATRIX**"""

# Confusion matrix
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues',
            xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

"""# **CONCLUSION**

Our model did a pretty good job! It was able to correctly predict whether a customer would accept a personal loan about 80% of the time. It handled both types of customers those who said yes and those who said no almost equally well, showing a good balance between being accurate and fair. This means the bank can confidently use this model to target the right people for future loan offers and avoid wasting time on those unlikely to respond.
"""